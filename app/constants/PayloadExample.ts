const exampleDocument = {
    "type": "result",
    "user_id": "051ae4aa-1841-5419-81e0-bbe2784f6632",
    "conversation_id": "8afc17c3-ebb0-48d1-8401-1bcad2409605",
    "query_id": "020e0455-6d92-4d0d-abc2-f203a7654833",
    "id": "res-14d0fc2d-d621-4c2a-b168-47f4b9dbfe98",
    "payload": {
        "type": "document",
        "objects": [
            {
                "content": "![Agents Simplified: What we mean in the context of AI](./img/hero.png)\n\n\nIf you’re in the AI-osphere, you’ve probably heard the term ‘AI Agents’ being thrown around quite a bit recently. In this article, let’s boil down what we mean when we say ‘Agents’ in the context of large language models (LLMs) and artificial intelligence (AI).\n\nBefore we dive into the topic, one thing to remember is that the term ‘agents’ has existed long before we had todays performant LLMs. We could even say that AI agents have existed for a long time too, just not with today’s generative LLMs as the star. What has changed though is just how good and sophisticated they’ve become. So, in short, you’re not hearing more about agents because they’re a brand new technology. No, you’re hearing more about AI agents because things just got very, very interesting.\n\n## What is an AI Agent\n\nAt a basic level, an AI agent today is a semi- or fully-autonomous system that uses an LLM as its ‘brain’ for critical decision making and solving complex tasks. Think of them as automated decision making engines so that you, the user, only have to come with your query. They operate and use a variety of tools available to them in their environment to get things done for you so that you can sit back and relax while it figures out how to solve your problem.\n\nAgents autonomously direct their own processes and execution flow, choosing which tools to use based on the task at hand. These tools can include web search engines, databases, APIs, and more, enabling agents to interact with the real world.\n\n## A Brief History on AI Agents\n\nAI agents have technically existed for a long time. You can even see the authors of [this recent article on AI agents by Microsoft](https://news.microsoft.com/source/features/ai/ai-agents-what-they-are-and-how-theyll-change-the-way-we-work/) referring to AI agents they’d been working on back in 2005. However, the shape and abilities of our AI agents have significantly changed in the last couple of years largely thanks to the abilities of the latest LLMs. Now, we’re able to use LLMs as a core component when it comes to planning, reasoning and acting.\n\n> Reader: This section was a pleasure for me (Tuana) to write and geek out on. But if history and research is not your thing, feel free to jump to the next section. I won’t take offense.\n\nSo, with that said, I’d like to highlight a few milestones in our _recent_ history of AI agents, and you can assume that from here on out we are only referring to the AI agents of today (2025). This is of course my own expecrience on the matter looking back over the last few years. But let’s turn back the clock to just before the release of ChatGPT. In 2020, there were 2 papers that were published that in my view could be viewed as the beginnings of current day AI agents that make use of LLMs as the core decision making component:\n\n-   [MRKL Systems](https://arxiv.org/abs/2205.00445): Pronounced ‘miracle’ systems, this paper was largely centered around the shortcomings of language and studied the _reason_ as to why we were getting so many hallucinated responses. And in short, they highlighted what we now fully understand: Language models don’t _know_ everything, they’re designed to generate language. Think of it this way, we can’t expect people to know our birthday unless we tell them when it is. This paper introduces a way in which we can provide language models with external knowledge bases which can be referred to extract the relevant information from.\n-   [ReAct](https://arxiv.org/pdf/2210.03629): Published slightly after MRKL systems, this paper introduced another crucial component into what makes an agent today. This paper introduced a process of prompting that we call “ReAct”, which stands for ‘reason and act’. In short, it highlighted a clever way we can structure our prompts which results in the LLM taking into account the question at hand, reasoning about its options on how to solve it, selecting the correct tools to use to solve the question, and acting on it. To keep things _very_ simple, take the following example. Instead of only asking the question, we’re also telling the model which resources it has access to and asking it to make a plan about how it would solve the query. In short, this paper introduced a way to start thinking about our LLM instructions to make the process of reasoning and acting more reliable:\n\n![chat](img/chat.png)\n\n> Note: The actual ReAct prompt recommended in the paper is a lot more involved than this, including instructions on how to generate thought, how to reason and so on.\n\nIn my view, these two papers highlight two very important findings and features that bring us to the AI agents of today: a good instruction, and external tools. That, and thousands of humans who started to tinker around with these LLMs and we’re now in a world where we’ve started to build more and more sophisticated AI agents (that no longer only use the ReAct prompting approach).\n\nWith that, let’s have a look into what makes up an AI agent of today.\n\n### Core Components of an AI Agent\n\nAlthough not every AI agent has to include _all_ of these components, when we build agents they include at least a few of the following components and processes: An LLM, access to tools (via function calling), some level of memory, and reasoning.\n\nLet’s dive into what they each do:\n\n-   **LLM:** Think of the LLM as the brain of the operation. Although not necessarily for _every step_, when we say ‘agents’ in 2025 a generative model is involved as the orchestrator of the operation to a great degree. Simply put, think of the example scenario in the section above: it’s the LLM that has decided that it’s best to first look up the `user_calendar` followed by looking up the weather.\n-   **Tools:** A great feature of agents is that they interact with the environment through different tools. One can think of them as ‘add-ons’ that make agents better. These tools let agents go beyond the fixed training knowledge of the LLMs by providing highly relevant and real-time data (like to your personal database) and abilities (like sending emails). With function calling, LLMs can directly interact with a predefined set of tools, expanding the operational scope and efficiency of agents.\n-   **Memory:** Agents often have some form of memory (both short-term and long-term), which allows them to store logs of their reasoning process, conversation histories, or information collected during different execution steps. We need memory both for ongoing conversations with our agents as well as conversations we want to come back to. Memory can be used to personalize the experience or plan future decisions\n-   **Observation & Reasoning:** The LLM is at the heart of problem solving, task decomposition, planning, and routing. It’s the component that allows the agent to reason about a problem, break it down into smaller steps (if needed), and decide how & when to use the available resources/tools to provide the best solution. However, not every agent is built equally, sometimes we include reasoning as an explicit step of the process when we’re building our agents.\n\nAn important thing to remember is that there are various design patterns that result in an AI agent and these components can be used to varying degrees. The agents we see today exist on a spectrum, and the level of autonomy or ‘agentic’ behavior largely depends on how much decision making authority is delegated to the LLMs. In simpler terms: some agents are designed to operate more independently than others.\n\n![agents](img/ai_agents.png)\n\n## How do AI Agents Work?\n\nMost AI agents we see today use the LLM as the core decision maker/orchestrator of the operation. The level of autonomy this LLM has can of course vary, which we’ll talk more about in the ‘A look into the future’ section of this article. But let’s first start by discussing the basics of how an AI agent that uses an LLM for most of the decisions works.\n\nSomething I notice is that when people discuss LLMs and agents these days, it seems like there’s quite a lot of magic happening. So here, I’ll try to explain what is _actually_ going on behind the scenes of an AI agent that has access to some tools.\n\n### Define the Prompt\n\nAt the heart of any system that uses an LLM is an instruction (a prompt) that sets the scene for the LLM as to what its core purpose is. The ReAct paper also clearly presented this by highlighting a complex prompt that defines a reasoning, thought-generating, observing agent. For example, an LLM could be given the instruction about how it’s a “helpful assistant that has access to my databases in order to answer my queries”.\n\n### Provide Tools\n\nNext, we need to provide a list of tools to the LLM. This is by far one of the most popular ways of creating AI agents today, although it’s not always necessary and we can still create agentic functionality without it having to be via tools and function calling. Most model providers today support ‘function calling’ which allows us to set up our interactions with an LLM with a list of tools that it knows it may access at any given time to resolve a query.\n\nWhen we provide tools to an LLM, we tell the LLM about a few things. It uses these things to decide whether it’s time to use the tool or not:\n\n-   **The name:** for example, a tool may have the name `technical_documentation_search`\n-   **The description:** which is probably the most important piece of information the model has access to when reasoning about which tool to use. For example, for the tool `technical_documentation_search` we may provide the description “Useful for when you need to search the Weaviate technical docs for answers”\n-   **The expected inputs:** Remember that tools are _external_ to the LLM. The LLM knows their name, it has a description for them too, but ultimately the job of a generative large language model is to produce language. So what can it do? Well, what it’s good at! It can probably produce some content which returns the name of a function (a tool), and the expected inputs for it to run. So, we also provide this information when we give a list of tools to an LLM. For example, for our tool `technical_documentation_search` tool, we may tell the LLM that it expects `query: str` to run.\n\nIf you’re interested in what this looks like in reality, you can check out the [Function Definition docs by OpenAI](https://platform.openai.com/docs/guides/function-calling) for example.\n\n### Use Tools\n\nSo, we have an LLM, it knows that it may access some tools, how to run them, and what they’re useful for. However, an LLM doesn’t have an inherent ability to, for example, run a python script… Or search your documentation. What it can do though is provide a message that _explains_ that it intends to run a tool, and what inputs it wants to run it with.\n\nLet’s take the following scenario as an example:\n\n-   We have an AI agent using an LLM\n-   We’ve provided `technical_documentation_search` as a tool with expected input `query: str`. We’ve said it’s “Useful for when you need to search the Weaviate technical docs for answers”\n-   User asks: “Hey, how can I use Ollama with Weaviate?”\n\nIn this scenario, what actually happens is something like this:\n\n-   The LLM produces a response that boils down to “Run tool `technical_documentation_search` with `query = \"Using Ollama\"` ”.\n\nSo, in reality, the LLM is making our AI agent application take a step outside of its own world. It instructs our system that there’s an external resource to be referenced.\n\n### Observe Tool Responses\n\nIf all goes well, by this point your AI agent has run a tool. Remember that this tool could be _anything_. For example, our `technical_documentation_search` tool could in itself be a [RAG application (retrieval augmented generation)](/blog/introduction-to-rag) that in itself uses yet another LLM to generate responses to queries. The point is, at the end of the day we’ve probably run the tool with the query “Using Ollama” and the response is “You can use Ollama by enabling the text2vec-ollama or generative-ollama modules, both for embedding models and generative modules”, or something along those lines. But that’s not the end of it, because the original LLM that makes up the core of our AI agent doesn’t know the response yet.\n\nWhen a tool runs, the results of that tool are then returned back to the agent’s LLM. This is usually provided as a chat message where the role is set to “function call”. So our LLM knows that the response it’s seeing is not from the user, but a result of the tool it decided to run. The LLM then observes the results of the tool (or tools) to provide the user with the final answer.\n\nCongratulations! By this point, you’ve learned the basics of what makes an AI agent! Especially those that rely on tools and function calling. The way I like to imagine it is that the LLM that is the core orchestrator of an AI agent is a bit like a wizard with a spell book but no wand. The LLM knows what it can do, and how, but it can do nothing more than say the magic word. The tools still have to run outside the LLM.\n\n![wizard](img/wizard.png)\n\n## What is “Agentic” AI\n\nThere’s a lot of new vocabulary to get used to, which can be confusing. But actually, when it comes to what’s “agentic AI” versus what an “AI agent” is, we can make our lives a lot easier. An AI agent is inherently _agentic_, but an AI agent usually refers to the an end application designed for a specific task. For example, an AI agent might be a documentation search assistant, or a personal assistant that has access to your email and slack.\n\nWhen we say ‘Agentic AI’ however, we’re usually to a system that is designed with elements of agentic components such as a decision making LLM, a reasoning step, maybe some tools, self-reflection, and so on. For something to be deemed agentic, it doesn’t need to have all of components. Rather, it often showcases the features of some of them.\n\n## Tools for Building AI Agents\n\nBuilding an AI agent requires integrating many components and tools to create a system capable of autonomous or semi-autonomous decision-making, interaction, and task execution. While advanced agents can be highly complex, even the simplest ones need a few essential elements. Below are some resources that can help you get started with building your own AI agents:\n\n### 1. Language Model Providers:\n\nThe foundation of an AI agent is an LLM, which powers its entire reasoning. It allows the agent to understand different inputs and plan its actions effectively. It is also essential to look for an LLM that has built-in function-calling support so that we can connect it to external tools and APIs. Popular LLM providers include:\n\n-   [OpenAI](https://platform.openai.com/docs/models): GPT 4o, o3-mini\n-   [Anthropic](https://docs.anthropic.com/en/docs/about-claude/models): Claude 3.5 Sonnet, Claude 3.5 Haiku\n-   [Google](https://ai.google.dev/gemini-api/docs/models/gemini): Gemini 2.0 Pro, Gemini 2.0 Flash\n-   [Mistral](https://docs.mistral.ai/getting-started/models/models_overview/): Mistral Large, Mistral Small 3\n-   Open-source models using [Hugging Face](https://huggingface.co/models) or [Ollama](https://ollama.com/search)\n\n### 2. Memory and Storage:\n\nAgents need some kind of persistent memory to retain context over time. The memory can be of two types:\n\n-   Short-term Memory: To keep track of current conversation or the task at hand.\n-   Long-term Memory: To remember past conversations, personalization, and experiences over time.\n\nThere are currently many variations and implementations of both types of memory for agents today, and we’re likely to see more as the technology progresses. For example, for short-term memory, we see implementations as simple as providing “conversation summaries” to the LLM at each iteration or message, so as to navigate context length limits. For long-term memory, we may choose to use a database to back up conversations. This may even start changing the role of vector databases like Weaviate, where they start being used as long-term memory which the AI agent can extract most relevant bits of prior conversation from.\n\n### 3. Frameworks for AI Agent Orchestration:\n\nOrchestration frameworks act as smart conductors, coordinating all components of an AI agent and even managing multiple agents in a multi-agent setup. They abstract away most of the complexities, handle errors/retries cycles, and ensure that the language model, external tools/APIs, and memory systems all work together smoothly.\n\nThere are several frameworks available that simplify the development of AI agents:\n\n-   [Langgraph](https://www.langchain.com/langgraph): Provides a structured framework for defining, coordinating, and executing multiple agents.\n-   [LlamaIndex](https://www.llamaindex.ai/): Enables the creation of complex, agentic systems with varying degrees of complexity.\n-   [CrewAI](https://www.crewai.com/): Multi-agent framework for orchestrating autonomous AI agents having specific roles, tools, and goals.\n-   [Hugging Face smolagents](https://huggingface.co/docs/smolagents/en/index): Library that enables you to run powerful agents in just a few lines of code.\n-   [Haystack](https://haystack.deepset.ai/): End-to-end framework that allows you to build AI applications like agents, powered by LLMs.\n-   [OpenAI Swarm](https://github.com/openai/swarm):An educational framework exploring ergonomic, lightweight multi-agent orchestration.\n- [AgentKit](https://agentkit.inngest.com/overview): A TypeScript library to create and orchestrate AI Agents.\n\n### 4. Tools and APIs:\n\nAn agent is only as powerful as the tools it can access. By connecting to various APIs and tools, the agent can interact with its environment and perform tasks such as web browsing, data retrieval, database queries, data extraction & analysis, code execution, etc.\n\nFrameworks like LlamaIndex, offer pre-made tool integrations like data loaders for PDFs, websites, and databases, as well as for apps like Slack, and Google Drive via [LlamaHub](https://llamahub.ai/). Similarly, [Langchain](https://python.langchain.com/docs/integrations/tools/) offers a wide range of similar tools that agents can readily use. Also, developers can always build custom tools as per their needs by wrapping APIs to introduce entire new functionalities. Recent works like [Querying Databases with Function Calling](https://arxiv.org/abs/2502.00032) even hint at the promise of function calling for database queries.\n\nIn a nutshell, building AI agents is a lot like assembling pieces of a puzzle. You start off with a good language model, add the right set of tools and APIs, and then add in memory so that the agent remembers what’s important. An orchestration framework can be used to make things simpler and tie things together, making sure every piece plays its part perfectly.\n\n## A look into the future of AI Agents: challenges and advances\n\nThe great thing about AI agents and agentic AI in general is that it’s still evolving every day. Although there’s a lot we didn’t discuss here from the challenges we see, to other core components of actually building AI agents for production, like observability, there are a few things that is probably worth highlighting when it comes to the future of AI agents.\n\nFor example, you may have already noticed that unless we take some time to intentionally design our agentic applications, it may seem that a lot (too much?) relies on an LLM making the right call, if you will. And in the case that the agent has access to search tools, or knowledge bases, maybe that’s ok. But what happens when the tool has access to your bank account and the agent can now buy you a very expensive one way ticket to Hawaii?\n\nA debate I’ve really been enjoying listening to is whether the use of AI agents is mostly as “research assistants” or as the “executors of our will”. Which is a simple, but important debate, and probably one on which our opinions change over time as LLMs get better, and we have better regulations and guard rails in the field of AI in general.\n\n### Levels of Autonomy & Human in the Loop\n\nNow you understand how an AI agent in its most basic form operates. But it’s not _necessary_ (or advisable) to have the LLM be the orchestrator of _everything_. We’re already seeing more and more agents that delegate the process to simpler, more deterministic systems. And in some cases, to humans. For example, we’ll probably see more and more of the scenario in which a human is supposed to approve an action before it can take place.\n\nWe’re even seeing tools like [Gorilla](https://github.com/ShishirPatil/gorilla) implement agents with “undo” functionality that allows a human to decide whether an action should be back tracked, adding a layer of human intervention into the process.\n\n### Multi-modal AI Agents\n\nMulti-modality refers to the ability to make use of more than one modality, i.e. the ability to go beyond just language (text) and incorporate images, videos, audio and so on. In a way, the technology is for the most part there. So, we will probably start seeing more and more AI agents that can interact with a variety of mediums, either as part of their tooling, or inherently if they make use of a multi-modal LLM. Think of an AI agent which you can ask to “create a cute cat video and forward it to my email”!\n\n### The role of vector databases\n\nAnother interesting topic, especially for us at Weaviate, is the potential for the role of [vector databases](/blog/what-is-a-vector-database) in AI to expand. So far, we’ve mostly been seeing vector databases used as knowledge sources which an agent can have access to. However, it’s not difficult to imagine a future in which we’re making use of vector databases, as well as other types of databases, as memory resources for our agent interactions.\n\n## Examples and Use Cases of AI agents\n\nAI agents are reshaping the way we work and this change is already visible across multiple industries. They shine brightest when we need a perfect blend of conversation with action. By automating repetitive tasks they not only increase the work efficiency but also improve the overall user experience. Here are some real-world examples of AI agents in action:\n\n### AI Research Agent\n\nAI research agents, or research assistants simplify the process of analyzing large amounts of data, spotting trend, and generating hypotheses. Today, we can already see people in academia or professionals at work using ChatGPT as a companion to help them gather information, to help them structure their thoughts and provide the first step in many tasks. In a way, ChatGPT in its bare form is in itself a research assistant agent. These types agents are also sometimes referred to as [“Agentic RAG”](/blog/what-is-agentic-rag), where an AI agent has access to multiple RAG tools, each accessing different knowledge bases.\n\n### Customer Service Agent\n\nAI customer service agents provide 24/7 support, handling inquiries, troubleshooting, and offering personalized interactions. They reduce wait times and let human agents take on more complex tasks. They can both act as research assistants for customers, getting answers to their queries quicker, as well as completing tasks for them.\n\n### Marketing & Sales Agent\n\nThese agents optimize marketing campaigns and sales processes by analyzing customer data, personalizing outreach, and automating repetitive tasks like lead qualification and email follow-ups.\n\n### Code Assistant Agent\n\nThese agents help developers by suggesting code, debugging errors, resolving tickets/issues, and even building new features. This enables developers to save time and focus on creative problem-solving. Examples of this are already out there with Cursor and Copilot.\n\n## Summary\n\nThis article gave a high level overview of what we mean when we say ‘AI agents’ in 2025, as well as giving a simple look into how they work. Although we did not go into all the technical details of different ‘agentic workflows’, another blog going into more technical detail is coming soon! We go through the components that help with the basic understanding of AI agents, such as prompts, tools, observing tool responses and reasoning about the final answer. Finally, we look into the future of AI agents, discuss the current short-comings and the advancements we could expect.\n\nA lot of the historical overview mentioned in this blog was also my (Tuana’s) subjective view looking over the past few years. If you do think I’m missing a curcial step, do let me know (DMs open on [X](https://x.com/tuanacelik))\n\nimport WhatsNext from '/_includes/what-next.mdx'\n\n",
                "title": "Blog Agents-simplified",
                "category": [
                    "Blog"
                ],
                "uuid": "4ba20a4673cb4e99a4b3be6246650d8a",
                "collection_name": "weaviate_blogs"
            },
            {
                "content": "![What Are Agentic Workflows? Patterns, Use Cases, Examples, and More](./img/hero.jpg)\n\nAI agents. Agentic AI. Agentic architectures. Agentic workflows. Agents are everywhere. But what are they really? And can they actually do anything?\n\nNew technology brings with it a muddled mixture of confusing terminology, wild expectations, and self-proclaimed online experts. In this article, we cut through the noise and hype surrounding AI agents to explain and illustrate a critical tenet of agentic AI: agentic workflows.\n\nAgents, completely on their own, can’t do much. They need to be given roles, goals, and structure to achieve their goals. This is where workflows come in.\n\nUnderstanding agentic workflows allows you to understand how and why AI agents operate as they do. To help you get there, we’ll go through the key components of AI agents, give you a concise definition of agentic workflows, explain what makes a workflow agentic, elaborate on key recurring patterns in agentic workflows, detail real-world examples and use cases, and give an honest overview of the benefits and challenges to using agentic workflows.\n\n## What are AI agents?\n\n**AI agents** are systems that combine LLMs for reasoning and decision-making with tools for real-world interaction, enabling them to complete complex tasks with limited human involvement. Agents are assigned specific roles and given varying degrees of autonomy to accomplish their end goal. They are also equipped with memory, allowing them to learn from past experiences and enhance their performance over time.\n\nFor a more in-depth explanation of AI agents, their history, and tools for building them, check out our recent blog post, [Agents Simplified: What we mean in the context of AI](/blog/ai-agents).\n\nTo better understand how AI agents fit into agentic workflows, we’ll explore the core components of AI agents.\n\n### Components of AI Agents\n\nAlthough AI agents are designed for semi-autonomous decision-making, they rely on a larger framework of components to function properly. This framework consists of LLMs that enable the agent to reason effectively, tools that help the agent complete its tasks, and memory that allows the agent to learn from past experiences and improve responses over time.\n\n![components-of-ai-agents.jpg](./img/components-of-ai-agents.jpg)\n\n#### Reasoning\n\nPart of what make AI agents so effective is their capacity for iterative reasoning, essentially allowing the agent to actively “think” throughout the entire problem-solving process. The reasoning capabilities of an AI agent stem from its underlying LLM and serve two primary functions: planning and reflecting.\n\nIn the **planning** phase, the agent performs **task decomposition**, the process of breaking down a more complex problem into smaller, actionable steps. This technique allows for agents to approach tasks systematically and allows them to use different tools for different tasks. It also allows for **query decomposition**, in which complex queries are broken down into simpler queries, which improves the accuracy and reliability of responses from the LLM.\n\nAgents also reason through **reflecting** on the outcomes of their actions. This allows them to evaluate and iteratively adjust their plan of action based on results and data pulled from external sources.\n\n#### Tools\n\nLLMs possess static, parametric knowledge, meaning their understanding is confined to the information encoded during training. To expand their capabilities beyond their original dataset, agents can leverage external **tools**, like web search engines, APIs, databases, and computational frameworks. This means that the agent has access to real-time external data to guide its decision-making and accomplish tasks that require it interact with other applications.\n\nTools are often paired with permissions, such as the ability to query APIs, send messages, or access specific documents or database schemas. The table below outlines several common tools for AI agents along with the tasks they perform.\n\n| **Tool** | **Task** |\n| --- | --- |\n| Internet search | Retrieve and summarize real-time information. |\n| Vector search | Retrieve and summarize external data. |\n| Code interpreter | Iteratively run code generated by agents. |\n| API | Retrieve real-time information and perform tasks with external services and applications. |\n\nWhen the LLM selects a tool to help achieve a task, it engages in a behavior called **function calling**, extending its capabilities beyond simple text generation and allowing it to interact with the real-world.\n\nThe choice of which tool to use can be predetermined by the end user or be left to the agent. Letting the agent dynamically select tools can be helpful for solving more complex tasks but can add unnecessary complexity for simpler workflows, when predefined tools would be more efficient.\n\n#### Memory\n\nLearning from past experiences and remembering the context in which actions take place are part of what set agentic workflows apart from purely LLM-driven workflows. **Memory** is a key component that enables the capture and storage of context and feedback across multiple user interactions and sessions. Agents have two main types of memory: short-term memory and long-term memory.\n\n**Short-term memory** stores more immediate information like conversation history, which helps the agent determine which steps to take next to complete its overall goal. **Long-term memory** stores information and knowledge accumulated over time, throughout multiple sessions, allowing for personalization of the agent and improved performance over time.\n\n## What are Agentic Workflows?\n\nIn general, a **workflow** is a series of connected steps designed to achieve a specific task or goal. The simplest types of workflows are deterministic, meaning they follow a predefined sequence of steps and are unable to adapt to new information or changing conditions. For example, an automated expense approval workflow could look like this: “if expense is tagged as ‘Food and Meals’ and is less than $30, automatically approve.”\n\nSome workflows, however, leverage LLMs or other machine learning models or techniques. These are often referred to as **AI workflows**, and can be agentic or non-agentic. In a non-agentic workflow, a LLM is prompted with an instruction and generates an output. For example, a text summarization workflow would take a longer passage of text as its input, prompt a LLM to summarize it, and simply return the summary. However, just because a workflow uses a LLM, doesn’t necessarily mean that it’s agentic.\n\nAn **agentic workflow** is a series of connected steps *dynamically executed by an agent*, or series of agents, to achieve a specific task or goal. Agents are granted permissions by their users, which  give them a limited degree of autonomy to gather data, perform tasks, and make decisions to be executed in the real-world. Agentic workflows also leverage the core components of AI agents including, their capacity for reasoning, ability to use tools to interact with their environment, and persistent memory to completely transform traditional workflows into responsive, adaptive, and self-evolving processes.\n\n![types-of-workflows.jpg](./img/types-of-workflows.jpg)\n\n### What makes a workflow agentic?\n\nAn AI workflow becomes agentic when one or more agents guide and shape the progression of tasks. Adding agents to an existing non-agentic workflow creates a hybrid approach that combines the reliability and predictability of structured workflows with the intelligence and adaptability of LLMs. Agentic workflows are defined by their ability to:\n\n- **Make a plan.** An agentic workflow starts with planning. The LLM is used to break down complex tasks into smaller sub-tasks through task decomposition and then determines the best execution route.\n- **Execute actions with tools.** Agentic workflows use a set of predefined tools paired with permissions in order to accomplish tasks and carry out their generated plan.\n- **Reflect and iterate.** Agents can assess results at each step, adjust the plan if needed, and loop back until the outcome is satisfactory.\n\nAs you can see, we need to differentiate between three types of workflows: traditional non-AI workflows, non-agentic AI workflows, and agentic workflows. The difference between a traditional, rule-based workflow and an AI workflow is the use of predefined steps vs. the use of AI models to accomplish a task. Second, the difference between non-agentic and agentic AI workflows is the use of static AI models vs. dynamic AI agents. This makes the agentic workflow more adaptive an dynamic than a non-agentic workflow.\n\n### The difference between agentic architectures and workflows\n\nWith any emerging technology, comes a flood of new terminology. While some may use the terms “agentic architectures” and “agentic workflows” interchangeably, they actually have an important distinction. \n\nAn **agentic workflow**, is the *series of steps* taken by an agent to achieve a certain goal. These steps may include using LLMs to create a plan, break down tasks into subtasks, using tools like internet search to accomplish tasks, and using LLMs to reflect on the outcomes of tasks and adjust their overall plan.\n\nAn **agentic architecture,** on the other hand, is the technical framework and *overall system design* used to achieve a given task. Agentic architectures are diverse and creative but always contain at least one agent with decision-making and reasoning capabilities, tools the agent can use to accomplish its goals, and systems for short-term and long-term memory.\n\n\nExplore the most powerful agentic architectures, visually illustrated for instant understanding. Download the free e-book [here](http://weaviate.io/ebooks/agentic-architectures?utm_source=agentic_workflows_blog&utm_medium=post&utm_campaign=agentic_architectures&utm_content=cta1).\n\n\n## Patterns in Agentic Workflows\n\nRecall that an agentic workflow is the structured series of steps taken to complete a specific task, also known as a final target. So when we talk about agentic workflows, we talk about specific patterns of behavior that enable agents to achieve their final target. The core components of AI agents, as we mentioned earlier, play a key role in agentic workflow patterns. The capacity for agents to reason facilitates both the planning and reflection patterns, while their ability to use tools to interact with their environment underlies the tool use pattern.\n\n### Planning Pattern\n\nThe planning design pattern allows agents to autonomously break down more complex tasks into  series of smaller and simpler tasks, a process known as **task decomposition**. Task decomposition leads to better results because it reduces the cognitive load on the LLM, improves reasoning, and minimizes hallucinations and other inaccuracies.\n\nPlanning is especially effective when the method to achieve a final target is unclear and adaptability in the problem solving process is paramount. For instance, an AI agent instructed to fix a software bug would likely use the planning to pattern to break down the task into subtasks like reading the bug report, identifying the relevant code sections, generating a list of potential causes, and finally selecting a specific debugging strategy. If the first attempt to fix the bug doesn’t work, the agent can read the error messages after execution and adapt its strategy. \n\nWhile planning can help agents better tackle more complex tasks, it can also lead to less predictable results than more deterministic workflows. As a result, it’s best to only use the planning pattern with tasks that require intense problem-solving and multi-hop reasoning.\n\n![planning-pattern.jpg](./img/planning-pattern.jpg)\n\n### Tool Use Pattern\n\nA significant constraint of generative LLMs is their reliance on pre-existing training data, meaning they cannot retrieve real-time information or verify facts beyond what they have previously learned. As a result, they may generate non-factual responses or “guess” when they don’t know the answer. [Retrieval Augmented Generation (RAG)](/blog/introduction-to-rag) helps mitigate this limitation by providing the LLM with relevant, real-time external data, enabling more accurate and contextually grounded responses.\n\nTool use, however, goes beyond naive RAG by allowing the LLM to *dynamically interact* with the real world, as opposed to simply retrieving data from it. In agentic workflows, the **tool use** pattern expands the capabilities of agents by allowing them to interact with external resources and applications, real-time data, or other computational resources.\n\nCommon tools include APIs, information retrieval (e.g. vector search), web browsers, machine learning models, and code interpreters. These tools are used to perform specific tasks, like searching the web, retrieving data from an external database, or reading or sending emails that help the agent achieve their target. \n\n![tool-use-pattern.jpg](./img/tool-use-pattern.jpg)\n\n### Reflection Pattern\n\nReflection is a powerful agentic design pattern that is relatively simple to implement and can lead to significant gains in improvement for agentic workflows. The **reflection pattern** is a self-feedback mechanism in which an agent iteratively evaluates the quality of its outputs or decisions before finalizing a response or taking further action. These critiques are then used to refine the agent's approach, correct errors, and improve future responses or decisions.\n\nReflection is particularly useful when the agent is unlikely to succeed in accomplishing its target goal on the first attempt, such as writing code. In this case, an agent may generate a code snippet, run it in a sandbox or execution environment, and iteratively feed errors back into the LLM with instructions to refine the code until it executes successfully. \n\nThe power of reflection lies in the agent’s ability to critique its own outputs and dynamically integrate those insights into the workflow, enabling continuous improvement without direct human feedback. These reflections can be encoded in the agent’s memory, allowing for more efficient problem-solving during the current user session and enabling personalization by adapting to user preferences and improve future interactions.\n\n![reflection-pattern.jpg](./img/reflection-pattern.jpg)\n\n## Agentic Workflows Use Cases\n\nAtomic design patterns, like planning and tool use, can be combined in creative ways to effectively leverage agentic AI for a variety of tasks across diverse domains. In addition to combining design patterns, AI agents can be provided with different combinations of tools and even be granted the ability to dynamically select tools as needed. They can also be integrated with human feedback loops and given varying levels of autonomy and decision-making powers. \n\nThese diverse configurations allow agentic workflows to be tailored for a wide range of tasks across industries. To demonstrate this, we outline two especially powerful use cases: agentic RAG and agentic research assistants.\n\n### Agentic RAG\n\n[Retrieval-Augmented Generation (RAG)](/blog/introduction-to-rag) is a framework that augments the knowledge of a LLM by providing it with relevant data retrieved from an external data source. [Agentic RAG](/blog/what-is-agentic-rag) incorporates one or more agents into the RAG pipeline. \n\nDuring the planning phase, an agent can break down complex queries into smaller subqueries through query decomposition or determine whether it needs to ask the user for additional information to complete the request.\n\nAn AI agent can also be used to evaluate the relevance and accuracy of retrieved data and responses before it’s passed on to the user. If the response is not satisfactory, the agent can reformulate the query, revisit the query decomposition step, or even create a new plan for responding to the query.\n\n![agentic-search-workflow.jpg](./img/agentic-search-workflow.jpg)\n\n\nAgentic workflows like this one can be built with different agentic architectures. If you are curious about potential architectures for the above workflow, download our [free e-book](http://weaviate.io/ebooks/agentic-architectures?utm_source=agentic_workflows_blog&utm_medium=post&utm_campaign=agentic_architectures&utm_content=cta2) on agentic architectures! \n\n\n### Agentic Research Assistants\n\nAgentic research assistants, also referred to as “deep research” by some AI companies, generate in-depth reports and detailed insights on complex topics by scouring the web and all sorts of external data. These leverage agentic RAG to retrieve information from the web and other external sources in response to user queries. What sets these assistants apart from traditional RAG, however, is their ability to *synthesize and analyze* information, as opposed to simply retrieving relevant data from external sources to enhance the output generated by a LLM. \n\nThis unique ability is attributed to a few features. First, agentic research assistant generally use LLMs that have been fine-tuned specifically for web browsing, task decomposition, and dynamic planning. Second, agents in these workflows actively seek user guidance, requesting additional information or clarification to better understand the final goal. Third, these agents are able to adapt their plans and change course depending on the information they retrieve. This means that they can pursue new, interesting angles when synthesizing novel information and query multiple data sources consecutively until they get the necessary data.\n\nAs a result, agentic research assistants are able to gain deeper insights, identify trends over time, and compile full reports on topics as opposed to simply retrieving existing knowledge. At the time of writing, [OpenAI](https://openai.com/index/introducing-deep-research/), [Perplexity](https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research), and [Google](https://blog.google/products/gemini/google-gemini-deep-research/) all have their own version of Deep Research publicly available.\n\n### Agentic Coding Assistants\n\nAgentic coding assistants can generate, refactor, refine, and debug code with minimal human intervention. Non-agentic coding assistants, like the first version of GitHub Copilot, are powered by generative LLMs fine-tuned to generate code, but are limited to doing just that — generating code. \n\nWhat makes a coding assistant agentic is its ability to interact with its environment by executing generated code and iteratively refine it based on execution results, errors, or feedback. These assistants can also be enabled with permissions to make changes to an existing code base by creating commits and PRs, like Anthropic’s [Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview), an important step in automating the software development process. Agentic coding assistants can also be used to suggest terminal commands and other code changes and additions and wait for explicit human approval before execution, like Cursor’s [Agent](https://docs.cursor.com/agent), allowing humans to be fully in control of the agent. Additionally, and importantly, agentic coding assistants can learn from their mistakes by encoding them in long-term memory, allowing them to grow smarter over time.\n\n## Agentic Workflow Examples\n\nNow that we’ve outlined some use cases for agentic workflows, we’ll take a more detailed look at the individual steps of the workflows of two real-world agents: [Claygent](https://www.clay.com/claygent) and [ServiceNow AI Agents](https://www.servicenow.com/products/ai-agents.html). Each workflow uses its own unique combination of patterns and tools, gives its agents varying degrees of autonomy and decision-making capabilities, and relies on different levels of human feedback and involvement.\n\n### Claygent (Clay)\n\nLead research and data enrichment can be a tedious task for growth and sales teams. [Clay](https://www.clay.com/), a data enrichment and outreach automation company, streamlines this process with [Claygent](https://www.clay.com/claygent)—an AI-powered research agent that continuously scans the web and internal databases to deliver real-time, actionable insights.\n\nSay you want to use Claygent to enrich a LinkedIn profile based on a list of names and email addresses and then send a personalized introduction message. First, you specify the fields of data you’re looking for (e.g. work experience, education, skills), which is injected into a pre-configured prompt template. The agent’s LLM processes the query, uses a web scraping tool to scour the web for a LinkedIn URL, and extracts the desired data from the LinkedIn profile. This data can then be sent to another LLM that you can instruct to summarize or analyze the enriched data however you want. The same LLM (or a different one) can then be used to create a personalized outreach message for each profile.\n\nClaygent is an example of a relatively flexible agentic workflow that can be customized in creative ways, while still providing guidance to agents through pre-configured prompt templates for specific tasks.\n\n### ServiceNow AI Agents\n\n[ServiceNow](https://www.servicenow.com/) is a cloud-based platform that streamlines and automates workflows across IT, operations, HR, and customer service domains. Their ServiceNow Platform now includes access to AI agents, intended to automate repetitive tasks and pre-existing workflows, while still leaving humans in full control of making decisions.\n\nHere’s an example of how an agentic workflow can help resolve a technical support case. The workflow is triggered when a customer submits a ticket for technical support. The information from the ticket is then passed to one or more agents that perform RAG on an internal IT support knowledge base. The agent summarizes the findings, analyzes similar cases, and generates a summary for the IT support specialist. Finally, it generates a recommendation for how to proceed, which the specialist can either approve or deny. \n\nServiceNow AI Agents represent an innovative but more cautious approach to deploying agents in production, giving them strict roles and tasks to accomplish and limited, if any, autonomy to make decisions that affect the end user or customer.\n\n\nWant to build your own agentic workflow? Check out [Building Agentic Workflows with Inngest](/blog/inngest-ai-workflows), where we show how to create an agentic dinner planner.\n\n\n## Benefits and Limitations of Agentic Workflows\n\nAI agents have rapidly moved beyond the machine learning community and into the mainstream. Given all the excitement, anticipation, and expectations around agentic AI, it can be difficult to separate hype from reality and understand its true capabilities and limitations. In this section, we give you a balanced view of the benefits, challenges, and limitations of agentic workflows.\n\n### Benefits of Agentic Workflows\n\nAgentic workflows go beyond traditional automation by enabling AI agents to plan, adapt, and improve over time. Unlike deterministic workflows, which follow fixed rules, agentic workflows can dynamically respond to complexity, refine their approach through feedback, and scale to handle more advanced tasks. This adaptability makes them particularly valuable in scenarios where flexibility, learning, and decision-making are essential. \n\nLet’s take a closer look at the benefits of agentic workflows:\n\n- **Flexibility, adaptability, and customizability.**\nStatic, deterministic workflows struggle to adapt to evolving situations and unexpected difficulties. Agentic workflows, on the other hand, offer the flexibility to adjust and evolve based on the task difficulty, ensuring they always stay relevant and give the best solution. They can also be customized by combining different patterns, enabling a modular design that allows iterative upgrades as needs and complexity grows.\n- **Improved performance on complex tasks.**\nBy breaking down complex tasks into smaller manageable steps (through task decomposition and planning), agentic workflows significantly outperform deterministic, zero-shot approaches.\n- **Self-correcting and continuous learning.**\nThe reflection pattern allows agentic workflow to evaluate their own actions, refine strategies, and improve outcomes over time. Utilizing both short- and long-term memory, they learn from past experiences to become more effective and personalized with each iteration.\n- **Operational efficiency and scalability.**\nAgentic workflows can automate repetitive tasks with high accuracy (if built right), reducing manual effort and operational costs in specific scenarios. They can also scale easily, making them ideal for handling larger workloads or complex systems.\n\nKeep in mind that AI agents are still an emerging technology, and that this list of benefits is likely to expand as researchers and users discover novel ways of incorporating agents into workflows. \n\n### Challenges and Limitations of Agentic Workflows\n\nDespite their benefits and innovative features, AI agents also come with a number of challenges and limitations. Because of their probabilistic nature, AI agents inherently add complexity to workflows. And just because agents *can* be used to automate processes, doesn’t mean that they *should* be used. Here are a few of the most notable challenges and limitations of agentic workflows:\n\n- **Unnecessary complexity for simple tasks.**\n    \n    AI agents can add overhead when used for straightforward workflows like form entry or basic data extraction. In cases where deterministic, rules-based automation is sufficient, introducing agents may lead to inefficiencies, extra expense, and possibly reduced performance.\n    \n- **Reduced reliability as a result of increased autonomy.**\n    \n    As agents gain more decision-making power within a workflow, their probabilistic nature can introduce unpredictability, making outputs less reliable and harder to control. Implementing and actively maintaining guardrails for agents and continually reviewing their granted permissions is critical.\n    \n- **Ethical and practical considerations.**\n    \n    Not all decisions should be delegated to AI systems. Using agents in high-stakes or sensitive areas requires careful oversight to ensure responsible deployment and prevent unintended consequences.\n    \n\nGiven these limitations, we recommend taking time to reflect on whether using an agent is truly necessary in a given workflow. Some questions to help you determine this may include:\n\n- Is the task complex enough to require adaptive decision-making, or would a deterministic approach suffice?\n- Would a simpler AI-assisted tool (such as RAG without an agent) achieve the same outcome?\n- Does the workflow involve uncertainty, changing conditions, or multi-step reasoning that an agent could handle more effectively?\n- What are the risks associated with giving the agent autonomy, and can they be mitigated?\n\n## Summary\n\nAgentic workflows are powerful tools to help automate the completion of complex tasks that require decision-making and reasoning. In this article, we reviewed the core components of AI agents, including, memory, tools, and reasoning capabilities and how they contribute to agentic workflows. We also discussed common workflow patterns, like planning, tool use, and reflection that can be used in isolation or combination to create dynamic workflows. Furthermore, we outlined two particularly effective use cases, [agentic RAG](/blog/what-is-agentic-rag) and agentic research agents, and described the workflows behind two agents already on the market, Clay’s Claygent and ServiceNow’s AI Agents. Finally, we touched on the benefits of agentic workflows as well as their limitations and challenges. \n\nThe technology behind AI agents is continuously evolving, as is our understanding of them. This article is intended to give you a basic understanding how AI agents function in workflows but is by no means an exhaustive exploration of the topic. \n\nFor a more detailed view and explanation of specific agentic architectures, download our free [e-book](http://weaviate.io/ebooks/agentic-architectures?utm_source=agentic_workflows_blog&utm_medium=post&utm_campaign=agentic_architectures&utm_content=cta3).\n\n[![Alt Text](./img/download-now-cta.jpg)](http://weaviate.io/ebooks/agentic-architectures?utm_source=agentic_workflows_blog&utm_medium=post&utm_campaign=agentic_architectures&utm_content=cta4)\n\n### Resource guide\n\n📃 [A Survey on the Memory Mechanism of Large Language Model based Agents](https://arxiv.org/abs/2404.13501) (arXiv paper)\n\n📃 [Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model Based Agents](https://arxiv.org/pdf/2405.10467) (arXiv paper)\n\n🎬 [Advanced AI Agents with RAG](https://www.youtube.com/watch?v=UoowC-hsaf0&list=PLTL2JUbrY6tVmVxY12e6vRDmY-maAXzR1&ab_channel=Weaviate%E2%80%A2VectorDatabase) (YouTube)\n\n📝 [What is Agentic RAG](/blog/what-is-agentic-rag)\n\n📝 [Agentic Design Patterns Part 2, Reflection](https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io) (Blog post)\n\n\nimport WhatsNext from '/_includes/what-next.mdx'\n\n\n\n",
                "title": "Blog Agentic-workflows",
                "category": [
                    "Blog"
                ],
                "uuid": "92b7c494642d4fadb94f9e3ce7f5d0c9",
                "collection_name": "weaviate_blogs"
            },
            {
                "content": "\n![AI in Prod London](./img/hero.png)  \n\n---\n\n**AI in Action: Lessons from the Real World**\n\nThe Weaviate team was in London last month, where the presentations were packed with insights from the field, real-world use cases, and inspiration for what’s next in AI. From streamlining development to tackling challenges in nuclear energy, here’s a recap of the standout moments.\n\n---\n  \n### **1. Mastering Vector Databases**\n\nOur CTO & Co-Founder, Etienne Dilocker dove deep into two emerging use cases for large-scale projects:\n\n- **E-commerce search** handling **1-10 billion embeddings** with sub-second queries, powered by HNSW indexing and smart optimizations.\n- **Email RAG** using a multi-tenant setup to process hundreds of thousands of smaller datasets with sub-second speed.\n\nBoth examples proved there’s no one-size-fits-all solution—your approach should depend on the data and the problem you’re solving.\n\n---\n\n### **2. OLIVER’s AI Sandbox and Experimentation**\n\nAndy Hoare, Senior Business Analyst, from the marketing agency **OLIVER** shared how the company scaled from 500 to 5,000 people in 10 years, while making AI experimentation a core part of their strategy. Their **AI Sandbox** has **1,250+ users**, generating **10,000 images a month** and powering **10 million chat interactions**.\n\nHe spoke about the following projects:\n\n- **Slipstream** is changing how clients and agencies work together by empowering clients to create more comprehensive and efficient briefs and allowing agencies to work smarter and faster.\n- **C2PA** is a transparency initiative for AI-generated content that enables OLIVER to maintain a duty of care to its clients and audiences and build trust as a content creator.\n- **Share of Model,** with Jellyfish, measures brand perception within AI models.\n\nAndy’s advice? Experiment often, fail fast, and find great tech partners to support your growth.\n\n\n    \n    \n\n\n---\n\n### **3. AI Meets Nuclear Decommissioning**\n\nWillem van Asperen and Derek Van Gelderen from **PA Consulting** shared their innovative use of AI in the nuclear sector. At **Sellafield Limited**, they’re solving business-critical challenges, like:\n\n- A wave of retirements shrinking their workforce by **20%** in the next five years.\n- Document reviews that used to take **12 months**.\n\nTheir solutions included:\n\n- **SLComply.ai**, which automates compliance and slashes administrative time by **90%**.\n- **DANI**, a GenAI-powered assistant that processes documents in minutes instead of months.\n- **Genie**, a system that connects LLMs, databases, and operational tools to make workflows seamless.\n\nPA Consulting’s use of Weaviate to scale its document and compliance tools highlights the power of vector search and AI in transforming workflows. By integrating Weaviate, they’re achieving greater efficiency, accuracy, and scalability all while remaining user centric.\n\n\n    \n\n\n---\n\n### **4. Building AI-Native Software with Unbody.io**\n\nAmir Huieh, CEO & Co-Founder of **unbody.io**, shared his journey from running a computer vision and NLP to founding Unbody, an AI-first startup. He broke down the difference between **AI-native** apps (where AI is the core) and **AI-enhanced** ones (where AI is just a bonus).\n\nAmir showed how integrating **Weaviate** helped his team streamline their development stack, cutting out unnecessary layers. Demos included:\n\n- A **healthcare platform** that matches patients with therapists.\n- An **AI blogging tool** that turns videos into full articles.\n- A **desktop organizer** for simplifying digital clutter.\n\nAnd the big news? **Unbody is going open source!** Amir invited the community to [jump in and contribute](http://unbody.io/blog/going-oss).\n\n\n    \n    \n\n\n---\n\n### **Key Takeaways**\n\nAcross every session, a few key themes stood out:\n\n- **Simplify where you can**: Merging AI and traditional stacks saves time and headaches.\n- **Experiment boldly**: Whether it’s a sandbox or open source, trying new things (and failing fast) is the way to grow.\n- **AI is solving real problems**: From nuclear compliance to blogging tools, the impact is tangible and exciting.\n\nThe future of AI is collaborative, creative, and just getting started. Let’s keep building, learning, and sharing!\n\n\n",
                "title": "Blog Recap-london-roadshow",
                "category": [
                    "Blog"
                ],
                "uuid": "e0317f8a43444d13833d7b8cce63e913",
                "collection_name": "weaviate_blogs"
            },
            {
                "content": "![AI-native infrastructure](./img/hero.png)\n\nIt was a beautiful fall morning in Orlando when I left the Grand Floridian, headed for the Gartner IT Symposium aboard the shuttle bus. I was eager to catch the keynote, though I hadn't studied who was speaking. Walking into the session, I found myself watching Jensen Huang, NVIDIA's CEO, in a fireside chat with Gartner's Daryl Plummer. Though I'd missed the first half, what I heard next made up for it: \"Vectorize all of your data.\"\n\nThis statement resonated deeply, not just because of its simplicity but because it underscored a fundamental shift in how we think about data and AI in the enterprise. The rapid evolution of generative AI has ushered in a new era—one where traditional data infrastructures no longer suffice.\n\n### The collapse of traditional, CRUD-based applications\n\nFast forward a few months. I'm sitting with Weaviate's co-founder, visionary and CEO [Bob van Luijt](https://www.linkedin.com/in/bobvanluijt/), discussing how the AI-native world will force every application to be rebuilt from the ground up. We shared a conviction that traditional CRUD-based apps would give way to AI-native agentic applications, with [vector databases](/blog/what-is-a-vector-database) like Weaviate at their core.\n\nShortly after, Satya Nadella, Microsoft’s CEO, made headlines with his own provocative statement on how traditional business applications are becoming obsolete. His vision aligned perfectly with what Bob and I had been discussing. His reasoning? In the AI-native era, business logic is migrating from hardcoded rules to autonomous AI agents capable of orchestrating operations across multiple systems. In this paradigm, traditional applications (reliant on static CRUD operations) are no match for agentic AI systems. \n\n### The Rise of Agentic AI: What it means for the enterprise \n\nOver the past few years, large language models and generative AI have completely changed how enterprises interact with their data, moving from static search results to systems that generate context-aware insights on demand. We’re now entering the age of Agentic AI—where AI doesn’t stop at giving answers; it continuously learns and takes action.\n\nJust last week, OpenAI unveiled Operator, an AI agent that can take actions directly through a web browser, acting on behalf of users in real-world scenarios. In one demo, the agent found and made a reservation at a local restaurant based on user preferences. In another, it ordered groceries from a delivery service based on a recipe. \n\nThese recent innovations offer a glimpse into AI's future, but what do they mean for enterprises looking to stay ahead of the curve? [Gartner recently predicted](https://www.gartner.com/en/articles/intelligent-agent-in-ai) that by 2028, 33% of enterprise software applications will include agentic AI, up from less than 1% in 2024, enabling 15% of day-to-day work decisions to be made autonomously.\n\nThere’s no doubt that the next three years will be transformative, but conversations with customers, analysts, and industry leaders reveal a clear consensus: general-purpose autonomous agents are still far from practical in the enterprise. This is due to both governance risks and technical limitations. The real opportunity in the near-term lies in deploying specialized AI agents for well-defined tasks and workflows. Use cases across customer support, software engineering, and data management and enrichment —where workflows are structured and early prototypes show strong potential—can deliver immense enterprise value and human productivity gains in the near-term.\n\n### Why you need an AI-native vector database \n\nThe ability to process, retrieve, and learn from unstructured and multimodal data at scale is a core requirement of agentic AI systems. Traditional databases were not designed for this complexity. Instead, AI-native vector databases have emerged as critical infrastructure for organizations seeking to enable these capabilities.\n\nWeaviate is an open-source AI-native database that empowers AI builders with: \n\n* **Scalable AI-Native Architecture:** Designed specifically for AI workloads, Weaviate delivers unparalleled scalability and performance, handling billions of vectors with ease.  \n    \n* **Real-time Semantic Search:** Beyond basic vector similarity, Weaviate incorporates hybrid techniques to ensure relevant and precise results. Real-time ingestion and querying help AI agents quickly adapt to new information.   \n    \n* **Integration with Agentic Frameworks:** Weaviate works with popular LLMs and agent tools like [LangChain](https://weaviate.io/developers/integrations/llm-agent-frameworks/langchain) and [LlamaIndex](https://weaviate.io/developers/integrations/llm-agent-frameworks/llamaindex), making it easier to build and deploy agentic workflows. \n\n* **Weaviate Agents:** Integrate new insights directly into the database, transform existing data, and improve agentic application intelligence over time.\n\n* **Governance, Compliance, and Security:** Flexible deployment, multi-tenancy, and strong security controls help you run agentic AI safely and meet enterprise standards without added complexity.\n\nJensen Huang's directive to \"vectorize all your data\" isn't just a passing trend – it's an imperative for survival in the AI era. As traditional business applications collapse and agentic AI becomes the new center of gravity for enterprise software, more organizations will adopt AI-native infrastructure for their use cases. \n\nWhy Weaviate? Because true enterprise readiness requires more than just [vector search](/blog/vector-search-explained). It demands battle-tested reliability, scalable architecture that can handle billions of vectors, seamless model integration, and the ability to support complex agentic architectures. Weaviate delivers on all these fronts while maintaining the speed and flexibility that modern AI applications demand.\n\nThe future speaks in vectors, and that future runs on Weaviate. For enterprises looking to thrive in the AI-native era, Weaviate offers a foundation for innovation, adaptability, and scalable intelligence. Together, we’re not just building software—we’re redefining what it can do.\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n",
                "title": "Blog Ai-native-infrastructure",
                "category": [
                    "Blog"
                ],
                "uuid": "3209b040028545b69af1a7105a9c185a",
                "collection_name": "weaviate_blogs"
            },
            {
                "content": "![Agentic Retrieval Augmented Generation (RAG)](./img/hero.png)\n\n\nWhile Retrieval-Augmented Generation (RAG) dominated 2023, [agentic workflows are driving massive progress in 2024](https://x.com/AndrewYNg/status/1770897666702233815?lang=en). The usage of AI agents opens up new possibilities for building more powerful, robust, and versatile Large Language Model(LLM)-powered applications. One possibility is enhancing RAG pipelines with AI agents in agentic RAG pipelines.\n\nThis article introduces you to the concept of agentic RAG, its implementation, and its benefits and limitations.\n\n## Fundamentals of Agentic RAG\n\nAgentic RAG describes an AI agent-based implementation of RAG. Before we go any further, let’s quickly recap the fundamental concepts of RAG and AI agents.\n\n### What is Retrieval-Augmented Generation (RAG)\n\n[Retrieval-Augmented Generation (RAG)](https://weaviate.io/blog/introduction-to-rag) is a technique for building LLM-powered applications. It leverages an external knowledge source to provide the LLM with relevant context and reduce hallucinations.\n\nA naive RAG pipeline consists of a retrieval component (typically composed of an embedding model and a vector database) and a generative component (an LLM). At inference time, the user query is used to run a similarity search over the indexed documents to retrieve the most similar documents to the query and provide the LLM with additional context.\n\n![Vanilla RAG](./img/Vanilla_RAG.png)\n\nTypical RAG applications have two considerable limitations: \n\n1. The naive RAG pipeline only considers one external knowledge source. However, some solutions might require two external knowledge sources, and some solutions might require external tools and APIs, such as web searches.\n2. They are a one-shot solution, which means that context is retrieved once. There is no reasoning or validation over the quality of the retrieved context.\n\n### What are Agents in AI Systems\n\nWith the popularity of LLMs, new paradigms of AI agents and multi-agent systems have emerged. AI agents are LLMs with a role and task that have access to memory and external tools. The reasoning capabilities of LLMs help the agent plan the required steps and take action to complete the task at hand.\n\nThus, the core components of an AI agent are:\n\n- LLM (with a role and a task)\n- Memory (short-term and long-term)\n- Planning (e.g., reflection, self-critics, query routing, etc.)\n- Tools (e.g., calculator, web search, etc.)\n\n![Components of an AI agent](./img/Components_of_an_AI_agent.png)\n\nOne popular framework is the [ReAct framework](https://arxiv.org/abs/2210.03629). A ReAct agent can handle sequential multi-part queries while maintaining state (in memory) by combining routing, query planning, and tool use into a single entity.\n\n> ReAct = Reason + Act (with LLMs)\n\n\nThe process involves the following steps:\n\n1. Thought: Upon receiving the user query, the agent reasons about the next action to take\n2. Action: the agent decides on an action and executes it (e.g., tool use)\n3. Observation: the agent observes the feedback from the action\n4. This process iterates until the agent completes the task and responds to the user.\n    \n    ![ReAct framework](./img/ReAct.png)\n    \n\n## What is Agentic RAG?\n\nAgentic RAG describes an AI agent-based implementation of RAG. Specifically, it incorporates AI agents into the RAG pipeline to orchestrate its components and perform additional actions beyond simple information retrieval and generation to overcome the limitations of the non-agentic pipeline.\n\n> Agentic RAG describes an AI agent-based implementation of RAG.\n\n### How does Agentic RAG work?\n\nAlthough agents can be incorporated in different stages of the RAG pipeline, agentic RAG most commonly refers to the use of agents in the retrieval component. \n\nSpecifically, the retrieval component becomes agentic through the use of retrieval agents with access to different retriever tools, such as:\n\n- Vector search engine (also called a query engine) that performs vector search over a vector index (like in typical RAG pipelines)\n- Web search\n- Calculator\n- Any API to access software programmatically, such as email or chat programs\n- and many more.\n\nThe RAG agent can then reason and act over the following example retrieval scenarios:\n\n1. Decide whether to retrieve information or not\n2. Decide which tool to use to retrieve relevant information\n3. Formulate the query itself \n4. Evaluate the retrieved context and decide whether it needs to re-retrieve.\n\n### Agentic RAG Architecture\n\nIn contrast to the sequential naive RAG architecture, the core of the agentic RAG architecture is the agent. Agentic RAG architectures can have various levels of complexity. In the simplest form, a single-agent RAG architecture is a simple router. However, you can also add multiple agents into a multi-agent RAG architecture. This section discusses the two fundamental RAG architectures.\n\n**Single-Agent RAG (Router)**\n\nIn its simplest form, agentic RAG is a router. This means you have at least two external knowledge sources, and the agent decides which one to retrieve additional context from. However, the external knowledge sources don't have to be limited to (vector) databases. You can retrieve further information from tools as well. For example, you can conduct a web search, or you could use an API to retrieve additional information from Slack channels or your email accounts.\n\n![Single Agent RAG System (Router).png](./img/Single_Agent_RAG_System_(Router).png)\n\n**Multi-agent RAG Systems**\n\nAs you can guess, the single-agent system also has its limitations because it's limited to only one agent with reasoning, retrieval, and answer generation in one. Therefore, it is beneficial to chain multiple agents into a multi-agent RAG application. \n\nFor example, you can have one master agent who coordinates information retrieval among multiple specialized retrieval agents. For instance, one agent could retrieve information from proprietary internal data sources. Another agent could specialize in retrieving information from your personal accounts, such as email or chat. Another agent could also specialize in retrieving public information from web searches. \n\n![Multi Agent RAG System.png](./img/Multi_Agent_RAG_System.png)\n\n### Beyond Retrieval Agents\n\nThe above example shows the usage of different retrieval agents. However, you could also use agents for purposes other than retrieval. The possibilities of agents in the RAG system are manifold.\n\n## Agentic RAG vs. (Vanilla) RAG\n\nWhile the fundamental concept of RAG (sending a query, retrieving information, and generating a response) remains the same, **tool use generalizes it,** making it more flexible and powerful.\n\nThink of it this way: Common (vanilla) RAG is like being at the library (before smartphones existed) to answer a specific question. Agentic RAG, on the other hand, is like having a smartphone in your hand with a web browser, a calculator, your emails, etc.\n\n|  | Vanilla RAG | Agentic RAG |\n| --- | --- | --- |\n| Access to external tools | No | Yes |\n| Query pre-processing | No | Yes |\n| Multi-step retrieval | No | Yes |\n| Validation of retrieved information | No | Yes |\n\n## Implementing Agentic RAG\n\nAs outlined earlier, agents are comprised of multiple components. To build an agentic RAG pipeline, there are two options: a language model with function calling or an agent framework. Both implementations get to the same result, it will just depend on the control and flexibility you want.\n\n### Language Models with Function Calling\n\nLanguage models are the main component of agentic RAG systems. The other component is tools, which enable the language model access to external services. Language models with function calling offer a way to build an agentic system by allowing the model to interact with predefined tools. Language model providers have added this feature to their clients.\n\nIn June 2023, [OpenAI released function calling](https://platform.openai.com/docs/assistants/tools/function-calling) for `gpt-3.5-turbo` and `gpt-4`. It enabled these models to reliably connect GPT’s capabilities with external tools and APIs. Developers quickly started building applications that plugged `gpt-4` into code executors, databases, calculators, and more.\n\n[Cohere](https://docs.cohere.com/v2/docs/tool-use) further launched their connectors API to add tools to the Command-R suite of models. Additionally, [Anthropic](https://docs.anthropic.com/en/docs/build-with-claude/tool-use) and [Google](https://ai.google.dev/gemini-api/docs/function-calling) launched function calling for Claude and Gemini. By powering these models with external services, it can access and cite web resources, execute code and more.\n\nFunction calling isn’t only for proprietary models. Ollama introduced tool support for popular open-source models like `Llama3.2`, `nemotron-mini`, and [others](https://ollama.com/search?c=tools).\n\nTo build a tool, you first need to define the function. In this snippet, we’re writing a function that is using Weaviate’s [hybrid search](https://weaviate.io/developers/weaviate/search/hybrid) to retrieve objects from the database:\n\n```python\ndef get_search_results(query: str) -> str:\n    \"\"\"Sends a query to Weaviate's Hybrid Search. Parses the response into a {k}:{v} string.\"\"\"\n    \n    response = blogs.query.hybrid(query, limit=5)\n    \n    stringified_response = \"\"\n    for idx, o in enumerate(response.objects):\n        stringified_response += f\"Search Result: {idx+1}:\\n\"\n        for prop in o.properties:\n            stringified_response += f\"{prop}:{o.properties[prop]}\"\n        stringified_response += \"\\n\"\n    \n    return stringified_response\n```\n\nWe will then pass the function to the language model via a `tools_schema`. The schema is then used in the prompt to the language model: \n\n```python\ntools_schema=[{\n    'type': 'function',\n    'function': {\n        'name': 'get_search_results',\n        'description': 'Get search results for a provided query.',\n        'parameters': {\n          'type': 'object',\n          'properties': {\n            'query': {\n              'type': 'string',\n              'description': 'The search query.',\n            },\n          },\n          'required': ['query'],\n        },\n    },\n}]\n```\n\nSince you’re connecting to the language model API directly, you’ll need to write a loop that routes between the language model and tools:\n\n```python\ndef ollama_generation_with_tools(user_message: str,\n                                 tools_schema: List, tool_mapping: Dict,\n                                 model_name: str = \"llama3.1\") -> str:\n    messages=[{\n        \"role\": \"user\",\n        \"content\": user_message\n    }]\n    response = ollama.chat(\n        model=model_name,\n        messages=messages,\n        tools=tools_schema\n    )\n    if not response[\"message\"].get(\"tool_calls\"):\n        return response[\"message\"][\"content\"]\n    else:\n        for tool in response[\"message\"][\"tool_calls\"]:\n            function_to_call = tool_mapping[tool[\"function\"][\"name\"]]\n            print(f\"Calling function {function_to_call}...\")\n            function_response = function_to_call(tool[\"function\"][\"arguments\"][\"query\"])\n            messages.append({\n                \"role\": \"tool\",\n                \"content\": function_response,\n            })\n    \n    final_response = ollama.chat(model=model_name, messages=messages)\n    return final_response[\"message\"][\"content\"]\n```\n\nYour query will then look like this:\n\n```python\nollama_generation_with_tools(\"How is HNSW different from DiskANN?\",\n                            tools_schema=tools_schema, tool_mapping=tool_mapping)\n```\n\nYou can follow along [this recipe](https://github.com/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/function-calling/ollama/ollama-weaviate-agents.ipynb) to recreate the above.\n\n### Agent Frameworks\n\nAgent Frameworks such as DSPy, LangChain, CrewAI, LlamaIndex, and Letta have emerged to facilitate building applications with language models. These frameworks simplify building agentic RAG systems by plugging pre-built templates together.\n\n- DSPy supports [ReAct](https://dspy-docs.vercel.app/deep-dive/modules/react/) agents and [Avatar](https://github.com/stanfordnlp/dspy/blob/main/examples/agents/avatar_langchain_tools.ipynb) optimization. Avatar optimization describes the use of automated prompt engineering for the descriptions of each tool.\n- [LangChain](https://www.langchain.com/) provides many services for working with tools. LangChain’s [LCEL](https://python.langchain.com/v0.1/docs/expression_language/) and [LangGraph](https://www.langchain.com/langgraph) frameworks further offer built-in tools.\n- [LlamaIndex](https://www.llamaindex.ai/) further introduces the QueryEngineTool, a collection of templates for retrieval tools.\n- [CrewAI](https://www.crewai.com/) is one of the leading frameworks for developing multi-agent systems. One of the key concepts utilized for tool use is sharing tools amongst agents.\n- [Swarm](https://github.com/openai/swarm) is a framework built by OpenAI for multi-agent orchestration. Swarm similarly focuses on how tools are shared amongst agents.\n- [Letta](https://docs.letta.com/introduction) interfaces reflecting and refining an internal world model as functions. This entails potentially using search results to update the agent’s memory of the chatbot user, in addition to responding to the question.\n\n## Why are Enterprises Adopting Agentic RAG\n\nEnterprises are moving on from vanilla RAG to building agentic RAG applications. [Replit released an agent](https://docs.replit.com/replitai/agent) that helps developers build and debug software. Additionally, [Microsoft announced copilots](https://blogs.microsoft.com/blog/2024/10/21/new-autonomous-agents-scale-your-team-like-never-before/) that work alongside users to provide suggestions in completing tasks. These are only a few examples of agents in production and the possibilities are endless.\n\n### Benefits of Agentic RAG\n\nThe shift from vanilla RAG to agentic RAG allows these systems to produce more accurate responses, perform tasks autonomously, and better collaborate with humans.\n\nThe benefit of agentic RAG lies primarily in the improved quality of retrieved additional information. By adding agents with access to tool use, the retrieval agent can route queries to specialized knowledge sources. Furthermore, the reasoning capabilities of the agent enable a layer of validation of the retrieved context before it is used for further processing. As a result, agentic RAG pipelines can lead to more robust and accurate responses.\n\n### Limitations of Agentic RAG\n\nHowever, there are always two sides to every coin. Using an AI agent a for subtask means incorporating an LLM to do a task. This comes with the limitations of using LLMs in any application, such as added latency and unreliability. Depending on the reasoning capabilities of the LLM, an agent may fail to complete a task sufficiently (or even at all). It is important to incorporate proper failure modes to help an AI agent get unstuck when they are unable to complete a task. \n\n## Summary\n\nThis blog discussed the concept of agentic RAG, which involves incorporating agents into the RAG pipeline. Although agents can be used for many different purposes in a RAG pipeline, agentic RAG most often involves using retrieval agents with access to tools to generalize retrieval. \n\nThis article discussed agentic RAG architectures using single-agent and multi-agent systems and their differences from vanilla RAG pipelines. \n\nWith the rise and popularity of AI agent systems, many different frameworks are evolving for implementing agentic RAG, such as LlamaIndex, LangGraph, or CrewAI.\n\nFinally, this article discussed the benefits and limitations of agentic RAG pipelines.\n\n## Further Resources\n\n- [Notebook](https://github.com/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/function-calling/openai/openai-swarm.ipynb) using Swarm\n- [Notebook](https://github.com/weaviate/recipes/tree/main/integrations/llm-agent-frameworks/letta) using Letta and Weaviate\n- [Notebooks](https://github.com/weaviate/recipes/tree/main/integrations/llm-agent-frameworks/function-calling/ollama) on using function calling in Ollama\n- [Notebook](https://github.com/weaviate/recipes/blob/main/integrations/llm-agent-frameworks/agentic-rag-benchmark/vanilla-rag-vs-agentic-rag.ipynb) on Vanilla RAG versus Agentic RAG\n\n\n",
                "title": "Blog What-is-agentic-rag",
                "category": [
                    "Blog"
                ],
                "uuid": "0f5cef296fbb418ea1e8d08dddc6c4a5",
                "collection_name": "weaviate_blogs"
            }
        ],
        "metadata": {
            "collection_name": "weaviate_blogs",
            "display_type": "document",
            "summarise_items": true,
            "query_text": "ethics in AI",
            "query_type": "hybrid",
            "chunked": false,
            "query_output": {
                "target_collections": [
                    "ml_wikipedia",
                    "weaviate_blogs"
                ],
                "search_type": "hybrid",
                "search_query": "ethics in AI",
                "sort_by": null,
                "filter_buckets": null,
                "limit": 5
            },
            "code": {
                "language": "python",
                "title": "Query",
                "text": "collection.query.hybrid(\n    query='ethics in AI',\n    limit=5\n)"
            }
        },
        "code": {
            "language": "python",
            "title": "Query",
            "text": "collection.query.hybrid(\n    query='ethics in AI',\n    limit=5\n)"
        }
    }
}